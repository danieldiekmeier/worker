"use strict";(self.webpackChunkgraphile_worker=self.webpackChunkgraphile_worker||[]).push([[350],{5318:(e,t,r)=>{r.d(t,{Zo:()=>p,kt:()=>d});var n=r(7378);function o(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function a(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,n)}return r}function s(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?a(Object(r),!0).forEach((function(t){o(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):a(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function i(e,t){if(null==e)return{};var r,n,o=function(e,t){if(null==e)return{};var r,n,o={},a=Object.keys(e);for(n=0;n<a.length;n++)r=a[n],t.indexOf(r)>=0||(o[r]=e[r]);return o}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(n=0;n<a.length;n++)r=a[n],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(o[r]=e[r])}return o}var l=n.createContext({}),u=function(e){var t=n.useContext(l),r=t;return e&&(r="function"==typeof e?e(t):s(s({},t),e)),r},p=function(e){var t=u(e.components);return n.createElement(l.Provider,{value:t},e.children)},c="mdxType",h={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},m=n.forwardRef((function(e,t){var r=e.components,o=e.mdxType,a=e.originalType,l=e.parentName,p=i(e,["components","mdxType","originalType","parentName"]),c=u(r),m=o,d=c["".concat(l,".").concat(m)]||c[m]||h[m]||a;return r?n.createElement(d,s(s({ref:t},p),{},{components:r})):n.createElement(d,s({ref:t},p))}));function d(e,t){var r=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var a=r.length,s=new Array(a);s[0]=m;var i={};for(var l in t)hasOwnProperty.call(t,l)&&(i[l]=t[l]);i.originalType=e,i[c]="string"==typeof e?e:o,s[1]=i;for(var u=2;u<a;u++)s[u]=r[u];return n.createElement.apply(null,s)}return n.createElement.apply(null,r)}m.displayName="MDXCreateElement"},6557:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>l,contentTitle:()=>s,default:()=>h,frontMatter:()=>a,metadata:()=>i,toc:()=>u});var n=r(5773),o=(r(7378),r(5318));const a={title:"Scaling tips"},s=void 0,i={unversionedId:"scaling",id:"scaling",title:"Scaling tips",description:"PostgreSQL is not what you'd build a job queue on if you're the size of",source:"@site/docs/scaling.md",sourceDirName:".",slug:"/scaling",permalink:"/docs/scaling",draft:!1,editUrl:"https://github.com/graphile/worker/tree/main/website/docs/scaling.md",tags:[],version:"current",frontMatter:{title:"Scaling tips"},sidebar:"tutorialSidebar",previous:{title:"Glossary",permalink:"/docs/glossary"}},l={},u=[{value:"Keep your jobs table small",id:"keep-your-jobs-table-small",level:2},{value:"Use the latest Graphile Worker release",id:"use-the-latest-graphile-worker-release",level:2},{value:"Do the vacuuming",id:"do-the-vacuuming",level:2},{value:"Don&#39;t just jump to another queue!",id:"dont-just-jump-to-another-queue",level:2}],p={toc:u},c="wrapper";function h(e){let{components:t,...r}=e;return(0,o.kt)(c,(0,n.Z)({},p,r,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("p",null,"PostgreSQL is not what you'd build a job queue on if you're the size of\nFacebook... But you're not the size of Facebook, right?"),(0,o.kt)("p",null,"Postgres can get you pretty far, processing over 10,000 jobs per second in our\nbenchmarks. That's ",(0,o.kt)("strong",{parentName:"p"},"almost a billion jobs per day"),". Using Postgres as your job\nqueue via Graphile Worker can keep your infrastructure simple, enabling you to\nfocus less on infrastructure and more on getting your product's features to\nmarket. But to maintain this performance, there's some things you must keep in\nmind."),(0,o.kt)("h2",{id:"keep-your-jobs-table-small"},"Keep your jobs table small"),(0,o.kt)("p",null,"Graphile Worker relies on the jobs table being small. v0.14.0 brought some\nimprovements that made it deal better with larger jobs tables, but the fastest\ntable to scan over is an empty one!"),(0,o.kt)("p",null,"Graphile Worker automatically deletes jobs when they are complete to keep the\njobs table small; however if a job perma-fails we leave it so that you can debug\nwhy it happened and handle the failure. ",(0,o.kt)("strong",{parentName:"p"},"You should clear up perma-failed jobs\nperiodically")," - either figure out why they failed, fix your task executor, and\nthen reduce the ",(0,o.kt)("inlineCode",{parentName:"p"},"attempts")," number of the job so that it'll try again; or simply\ndelete the jobs."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-sql"},"-- WARNING: untested!\ndelete from graphile_worker.jobs where attempts = max_attempts and locked_at is null;\n")),(0,o.kt)("p",null,"Jobs scheduled to run in the future can also keep the number of jobs in the jobs\ntable higher, impacting peak performance. Be thoughtful about these tasks, and\nconsider batching if it becomes an issue."),(0,o.kt)("h2",{id:"use-the-latest-graphile-worker-release"},"Use the latest Graphile Worker release"),(0,o.kt)("p",null,"We're constantly trying to improve the performance of worker; not just the peak\nperformance in the best situations, but also the baseline performance when\nthings are not at their best. v0.14.0 brought some major performance\nimprovements when the job queue is full of future-scheduled or perma-failed\njobs, for example."),(0,o.kt)("h2",{id:"do-the-vacuuming"},"Do the vacuuming"),(0,o.kt)("p",null,"The jobs table has extremely high churn; find a quiet period and give it a nice\n",(0,o.kt)("inlineCode",{parentName:"p"},"VACUUM")," from time to time."),(0,o.kt)("p",null,"TODO: which ",(0,o.kt)("inlineCode",{parentName:"p"},"VACUUM")," options should we recommend? Any other tables to VACUUM?"),(0,o.kt)("h2",{id:"dont-just-jump-to-another-queue"},"Don't just jump to another queue!"),(0,o.kt)("p",null,"If you're thinking about moving to another worker (and, when you reach the scale\nto justify that, you should - generally start thinking about it when you're\ngetting to 5k+ jobs per second), I have plans that I've not had time to\nimplement w.r.t. batch exporting jobs to external queues. This may allow us to\nget 10x or even 100x the speed since Worker needs to do less - this would mean\nyou don't need to rewrite the code that calls Worker, just the tasks themselves\nwould be implemented in another queue. If/when this is of interest, get in\ntouch!"),(0,o.kt)("p",null,"Also if you are suffering some acute performance issue and you can replicate\nyour load onto a staging server or similar I'd love to run some experiments to\nsee if we can't squeeze more performance out of the system."))}h.isMDXComponent=!0}}]);